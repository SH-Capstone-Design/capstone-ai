from typing import List, Dict, Tuple
import os
import torch
from kc_ai_app.model.model_loader import load_model
from kc_ai_app.src.label_map import LABEL_DISPLAY_MAP

LABELS = ["ê¸°ì¨", "ì„¤ë ˜", "ì• ì •", "í¸ì•ˆí•¨", "ë†ë‹´", "ìŠ¬í””", "ì„œìš´í•¨", "ì‹¤ë§", "í›„íšŒ", "ë¯¸ì•ˆí•¨", "ì§œì¦", "í™”ë‚¨", "ì§ˆíˆ¬", "ë¶ˆì•ˆ", "ì˜ì‹¬", "ì¤‘ë¦½"]

# ë””ë°”ì´ìŠ¤ ì„ íƒ (í™˜ê²½ë³€ìˆ˜ DEVICEê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ê¸°ë³¸ì€ cpu)
DEVICE = os.getenv("DEVICE") or ("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸/í† í¬ë‚˜ì´ì €ëŠ” í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹œ 1íšŒ ë¡œë“œ
# load_modelì€ ì´ì œ íŒŒì¸íŠœë‹ ëª¨ë¸ë§Œ ë¡œë“œí•˜ê³ , ê²½ë¡œê°€ ì—†ìœ¼ë©´ ì˜ˆì™¸ë¥¼ ë˜ì§€ë„ë¡ ë³€ê²½ë¨
tokenizer, model = load_model(device=DEVICE)

def _softmax_logits(logits) -> List[float]:
    # ë°°ì¹˜=1 ê°€ì •: dim=-1ë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í›„ 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    return torch.nn.functional.softmax(logits, dim=-1).squeeze(0).tolist()

def _aggregate_display_scores(scores: Dict[str, float]) -> Dict[str, float]:
    """ğŸ”¹ ì„¸ë¶€ ê°ì •ì„ ëŒ€í‘œ ê°ì • ê¸°ì¤€ìœ¼ë¡œ í•©ì‚°"""
    aggregated: Dict[str, float] = {}
    for sub_label, prob in scores.items():
        display_label = LABEL_DISPLAY_MAP.get(sub_label, sub_label)
        aggregated[display_label] = aggregated.get(display_label, 0.0) + prob
    return {k: round(v, 4) for k, v in aggregated.items()}

def analyze_sentence(sentence: str) -> Tuple[Dict[str, float], str, float]:
    """
    ë¬¸ì¥ ë‹¨ì¼ ë¶„ì„(ë¬¸ë§¥ ë¯¸ì‚¬ìš©). í•„ìš” ì‹œ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©.
    """
    inputs = tokenizer(sentence, return_tensors="pt", truncation=True, padding=True, max_length=128)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        probs = _softmax_logits(outputs.logits)

    # ì›ë³¸ ê°ì • í™•ë¥ 
    raw_scores = {LABELS[i]: probs[i] for i in range(len(LABELS))}

    # ğŸ”¹ ëŒ€í‘œ ê°ì •ìœ¼ë¡œ í•©ì‚°
    display_scores = _aggregate_display_scores(raw_scores)

    # ğŸ”¹ ëŒ€í‘œ ê°ì • ì¤‘ ìµœëŒ€ê°’ ì„ íƒ
    best_label = max(display_scores, key=display_scores.get)
    confidence = display_scores[best_label]

    return display_scores, best_label, float(confidence)

def _build_context_text(history: List[Dict[str, str]], current: Dict[str, str], context_size: int = 2) -> str:
    """
    ì§ì „ Nê°œì˜ ë°œí™”(context_size) + í˜„ì¬ ë°œí™”ë¥¼ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ ì—°ê²°.
    ìŠ¤í”¼ì»¤ ì •ë³´ë„ í•¨ê»˜ ë„£ì–´ ë¬¸ë§¥ì„ ë³´ì¡´.
    history: [{"speaker": "BF", "text": "..."}, ...]
    current: {"speaker": "...", "text": "..."}
    """
    ctx = history[-context_size:] if context_size > 0 else []
    parts = [f"[{utt['speaker']}] {utt['text']}" for utt in ctx]
    parts.append(f"[{current['speaker']}] {current['text']}")
    return " ".join(parts)

def analyze_sentence_with_context(history: List[Dict[str, str]], current: Dict[str, str], context_size: int = 2) -> Tuple[Dict[str, float], str, float]:
    """
    ë¬¸ë§¥/ëŒ€í™” íë¦„ì„ ë°˜ì˜í•œ ë¬¸ì¥ ë¶„ì„.
    """
    text = _build_context_text(history, current, context_size=context_size)
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=256)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        probs = _softmax_logits(outputs.logits)

    raw_scores = {LABELS[i]: probs[i] for i in range(len(LABELS))}
    display_scores = _aggregate_display_scores(raw_scores)
    best_label = max(display_scores, key=display_scores.get)
    confidence = display_scores[best_label]

    return display_scores, best_label, float(confidence)
