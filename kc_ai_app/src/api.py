# kc_ai_app/src/api.py
from fastapi import FastAPI, Depends, HTTPException, Header
from pydantic import BaseModel, Field
from typing import List, Dict, Optional, Any, Union
from datetime import datetime, timezone
import os
from dotenv import load_dotenv
from pathlib import Path
import dateutil.parser
from collections import defaultdict

# ==============================
# í™˜ê²½ ë³€ìˆ˜ / ì¸ì¦ (ë¨¼ì €, ëª…ì‹œ ê²½ë¡œë¡œ ë¡œë“œ!)
# ==============================
ROOT = Path(__file__).resolve().parents[1]            # .../AI
ENV_KC_APP = ROOT / "kc_ai_app" / ".env"              # ìš°ì„  í›„ë³´
ENV_ROOT   = ROOT / ".env"                            # ëŒ€ì•ˆ í›„ë³´

if ENV_KC_APP.exists():
    load_dotenv(ENV_KC_APP)
elif ENV_ROOT.exists():
    load_dotenv(ENV_ROOT)
else:
    pass

API_KEY = os.getenv("API_KEY")
if not API_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (kc_ai_app/.env ë˜ëŠ” ë£¨íŠ¸ .env í™•ì¸)")

if not os.getenv("FINETUNED_MODEL_PATH"):
    os.environ["FINETUNED_MODEL_PATH"] = str((ROOT / "models" / "kcelectra-base-emotion").resolve())

def get_api_key(x_api_key: str = Header(..., alias="x-api-key")):
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid or missing API Key")
    return x_api_key

# ==============================
# ë¼ë²¨: 8ê°œ ê³ ì •
# ==============================
LABELS8: List[str] = ["ê¸°ì¨", "ì„¤ë ˜", "ì‹¤ë§", "í›„íšŒ", "ìŠ¬í””", "ì§œì¦", "ë¶ˆì•ˆ", "ì¤‘ë¦½"]

def _clamp01(x: float) -> float:
    if x < 0.0: return 0.0
    if x > 1.0: return 1.0
    return x

# ==============================
# ë°˜ì˜¬ë¦¼ ìœ í‹¸(í‘œì‹œìš©)
# ==============================
ROUND_DIGITS = 2  # ì†Œìˆ˜ 2ìë¦¬ ê³ ì •

def _round_scores(d: Dict[str, float], nd: int = ROUND_DIGITS) -> Dict[str, float]:
    return {k: round(float(v), nd) for k, v in d.items()}

def _round_nested(d: Dict[str, Dict[str, float]], nd: int = ROUND_DIGITS) -> Dict[str, Dict[str, float]]:
    out = {}
    for k, sub in d.items():
        out[k] = _round_scores(sub, nd) if isinstance(sub, dict) else sub
    return out

# ==============================
# FastAPI ì•±
# ==============================
app = FastAPI(title="Emotion Analysis API")

def to_dict(model: BaseModel) -> Dict:
    return model.model_dump() if hasattr(model, "model_dump") else model.dict()

# ===== ìš”ì²­ ìŠ¤í‚¤ë§ˆ =====
class EmotionRequest(BaseModel):
    """
    speaker: "BF" | "GF" | ì‹¤ì œ userId(ë¬¸ìì—´/UUID/ìˆ«ì) í—ˆìš©
    """
    speaker: str
    sentence: str
    sent_at: Optional[str] = None
    emotion_label: Optional[str] = None
    confidence: Optional[float] = None
    analyzed_at: Optional[str] = None

class ChatSession(BaseModel):
    chat_session_id: str
    couple_id: Union[int, str]
    start_at: str
    end_at: str
    duration_minutes: int

class ChatRequest(BaseModel):
    chat_session: ChatSession
    emotions: List[EmotionRequest]
    # ğŸ”‘ ì—­í• -ì‚¬ìš©ì ë§¤í•‘: {"BF":"<userId>", "GF":"<userId>"}
    role_binding: Dict[str, str] = Field(default_factory=dict)

# ===== ì‘ë‹µ ìŠ¤í‚¤ë§ˆ =====
class EmotionResponse(BaseModel):
    # âœ… ê·œê²©: speaker = ì‹¤ì œ userId ë¬¸ìì—´
    speaker: Optional[str] = None
    # ì°¸ê³ ìš©(í”„ë¡ íŠ¸/ë°±ì—”ë“œ ë””ë²„ê¹…ì— ìœ ìš©)
    userId: Optional[str] = None
    alias: Optional[str] = None  # "BF"/"GF" ë“± ë³„ì¹­(ìˆìœ¼ë©´)

    sentence: str
    scores: Dict[str, float]      # í•­ìƒ 8ë¼ë²¨ í‚¤ë¡œ ë°˜í™˜
    emotion_label: str
    confidence: float
    analyzed_at: str
    sent_at: Optional[str] = None

# ===== ê³µìš© ìœ í‹¸ =====
def _parse_iso(s: str):
    return dateutil.parser.isoparse(s)

def _to_utc_floor_min(dt):
    return dt.astimezone(timezone.utc).replace(second=0, microsecond=0)

def _get(emo: Any, key: str):
    if hasattr(emo, key): return getattr(emo, key)
    if isinstance(emo, dict): return emo.get(key)
    return None

def _get_ts(emo: Any):
    return _get(emo, "sent_at")

def _get_scores(emo: Any) -> Dict[str, float]:
    s = _get(emo, "scores") or {}
    return s

def _normalize_labels(scores: Dict[str, float]) -> Dict[str, float]:
    """
    8ë¼ë²¨ ê³ ì • ë¶„í¬ë¡œ ì •ê·œí™”:
      - 8í‚¤ ì™¸ì˜ í‚¤ëŠ” ë¬´ì‹œ
      - ëˆ„ë½ëœ í‚¤ëŠ” 0ìœ¼ë¡œ ì±„ì›€
      - í•©=1ë¡œ ì¬ì •ê·œí™”
    """
    merged = {k: float(scores.get(k, 0.0)) for k in LABELS8}
    s = sum(merged.values())
    if s > 0:
        merged = {k: _clamp01(v / s) for k, v in merged.items()}
    else:
        merged = {k: 0.0 for k in LABELS8}
    return merged

def _assert_inference_ready(emotions: List[Any]) -> None:
    missing = [i for i, e in enumerate(emotions) if not _get_scores(e)]
    if missing:
        raise ValueError(
            f"[aggregation] ì¶”ë¡  ì´í›„ ë°ì´í„°ê°€ ì•„ë‹˜: scores ì—†ëŠ” ë ˆì½”ë“œ {len(missing)}ê°œ "
            f"(ì˜ˆ: indices={missing[:10]}). ë¨¼ì € ê°ì •ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
        )

# ===== speaker â†’ userId í•´ì„ =====
def _looks_like_uuid_or_id(s: str) -> bool:
    if not isinstance(s, str): 
        return False
    # ë§¤ìš° ëŠìŠ¨í•œ ê²€ì‚¬: UUID/ìˆ«ì/í˜¼í•© ë¬¸ìì—´ í—ˆìš©
    return True if len(s) >= 1 else False

def _resolve_user_id(emo: EmotionRequest, role_binding: Dict[str, str]) -> Optional[str]:
    spk = (emo.speaker or "").strip()
    if spk in ("BF", "GF"):
        uid = role_binding.get(spk)
        return str(uid) if uid is not None else None
    # ì´ë¯¸ userIdë¥¼ ì§ì ‘ ë„£ì–´ì¤€ ê²½ìš°
    if _looks_like_uuid_or_id(spk):
        return spk
    return None

def _alias_of(uid: Optional[str], role_binding: Dict[str, str]) -> Optional[str]:
    if uid is None:
        return None
    for k, v in role_binding.items():
        if str(v) == str(uid):
            return k  # "BF" ë˜ëŠ” "GF"
    return None

# ===== ì§‘ê³„: userId í‰ë©´ í‚¤ {userId}_avg_scores =====
def calculate_aggregated_user_centric(
    emotions: List[EmotionResponse],
    start_at: str,
    end_at: str,
    role_binding: Dict[str, str]
) -> Dict[str, Any]:
    """
    ì¶œë ¥:
      timeline[i] = {
        "minute": <int>,
        "avg_scores": {...},
        "<userId>_avg_scores": {...},   # ì‚¬ìš©ì ìˆ˜ ë§Œí¼ ë°˜ë³µ
        ...
      }
      overall = {
        "avg_scores": {...},            # ì „ì²´ í‰ê· 
        "<userId>_avg_scores": {...},   # ì‚¬ìš©ì ìˆ˜ ë§Œí¼ ë°˜ë³µ
        ...
      }
    deprecated: ì„ íƒì ìœ¼ë¡œ bf/gf í•˜ìœ„í˜¸í™˜ ì œê³µ
    """
    _assert_inference_ready([to_dict(e) for e in emotions])

    start_dt = _parse_iso(start_at)
    end_dt   = _parse_iso(end_at)
    if start_dt.tzinfo is None: start_dt = start_dt.replace(tzinfo=timezone.utc)
    if end_dt.tzinfo   is None: end_dt   = end_dt.replace(tzinfo=timezone.utc)
    start_min = _to_utc_floor_min(start_dt)
    end_min   = _to_utc_floor_min(end_dt)
    total_minutes = int((end_min - start_min).total_seconds() // 60)
    if total_minutes <= 0:
        raise ValueError(f"[aggregation] ì„¸ì…˜ ì‹œê°„ì´ 0ë¶„ì…ë‹ˆë‹¤. start_at={start_at}, end_at={end_at}")

    minute_buckets: Dict[int, List[EmotionResponse]] = defaultdict(list)
    for emo in emotions:
        if not emo.sent_at:
            continue
        ts_min = _to_utc_floor_min(_parse_iso(emo.sent_at))
        minute = int((ts_min - start_min).total_seconds() // 60)
        if 0 <= minute < total_minutes:
            minute_buckets[minute].append(emo)

    if not minute_buckets:
        return {
            "interval": "1min",
            "timeline": [],
            "overall": { "avg_scores": {l: 0.0 for l in LABELS8} },
            "deprecated": {}
        }

    def _avg(sum_dict: Dict[str, float], denom: int) -> Dict[str, float]:
        return {lab: _clamp01(sum_dict.get(lab, 0.0) / max(denom, 1)) for lab in LABELS8}

    # ì „ì²´ í•©ì‚°
    overall_sum: Dict[str, float] = defaultdict(float)
    overall_cnt = 0
    # per-user í•©ì‚°
    per_user_sum: Dict[str, Dict[str, float]] = defaultdict(lambda: defaultdict(float))
    per_user_cnt: Dict[str, int] = defaultdict(int)

    timeline: List[Dict[str, Any]] = []

    for minute in sorted(minute_buckets.keys()):
        emos = minute_buckets[minute]

        # ë¶„ ì „ì²´
        sum_all: Dict[str, float] = defaultdict(float)
        n_all = 0
        # ë¶„ per-user
        sum_user: Dict[str, Dict[str, float]] = defaultdict(lambda: defaultdict(float))
        cnt_user: Dict[str, int] = defaultdict(int)

        for emo in emos:
            sc = emo.scores
            for lab, v in sc.items():
                sum_all[lab] += v
                overall_sum[lab] += v
            n_all += 1
            overall_cnt += 1

            if emo.userId is not None:
                uid = str(emo.userId)
                for lab, v in sc.items():
                    sum_user[uid][lab] += v
                    per_user_sum[uid][lab] += v
                cnt_user[uid] += 1
                per_user_cnt[uid] += 1

        minute_obj: Dict[str, Any] = {
            "minute": minute,
            "avg_scores": _round_scores(_avg(sum_all, n_all)),
        }
        # âœ… ê° ì‚¬ìš©ìì— ëŒ€í•´ "<userId>_avg_scores" í‚¤ ìƒì„±
        for uid, c in cnt_user.items():
            minute_obj[f"{uid}_avg_scores"] = _round_scores(_avg(sum_user[uid], c))

        timeline.append(minute_obj)

    # overall
    overall_obj: Dict[str, Any] = {
        "avg_scores": _round_scores(_avg(overall_sum, overall_cnt)),
    }
    # âœ… ì‚¬ìš©ìë³„ í‚¤
    for uid, c in per_user_cnt.items():
        overall_obj[f"{uid}_avg_scores"] = _round_scores(_avg(per_user_sum[uid], c))

    # (ì„ íƒ) í•˜ìœ„í˜¸í™˜(bf/gf) ì œê³µ
    deprecated_obj: Dict[str, Any] = {}
    bf_id = role_binding.get("BF")
    gf_id = role_binding.get("GF")
    if bf_id is not None and f"{bf_id}_avg_scores" in overall_obj:
        deprecated_obj["bf_avg_scores"] = overall_obj[f"{bf_id}_avg_scores"]
    if gf_id is not None and f"{gf_id}_avg_scores" in overall_obj:
        deprecated_obj["gf_avg_scores"] = overall_obj[f"{gf_id}_avg_scores"]

    return {
        "interval": "1min",
        "timeline": timeline,
        "overall": overall_obj,
        "deprecated": deprecated_obj
    }

# ===== í—¬ìŠ¤ì²´í¬ =====
@app.get("/health")
def health():
    return {"status": "ok"}

# ===== ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸ =====
@app.post("/analyze")
def analyze_chat(request: ChatRequest, api_key: str = Depends(get_api_key)):
    """
    ë¬¸ë§¥ ë°˜ì˜: ì§ì „ Nê°œ(history)+í˜„ì¬ ë°œí™”ë¡œ ë¶„ì„ (ê¸°ë³¸ N=2)
    speakerëŠ” "BF"/"GF" ë˜ëŠ” ì‹¤ì œ userId ë¬¸ìì—´ í—ˆìš©.
    ì‘ë‹µì—ì„œëŠ” ë°˜ë“œì‹œ speakerì— ì‹¤ì œ userIdë¥¼ ë„£ì–´ ë°˜í™˜.
    """
    # ì§€ì—° ì„í¬íŠ¸
    from .inference import analyze_sentence_with_context

    analyzed_emotions: List[EmotionResponse] = []
    history: List[Dict[str, str]] = []

    for emo in request.emotions:
        # === ì¶”ë¡  ===
        current = {"speaker": emo.speaker, "text": emo.sentence}
        scores, label, confidence = analyze_sentence_with_context(history, current, context_size=2)

        # 8ë¼ë²¨ ë¶„í¬ ë³´ì • ë° ë°˜ì˜¬ë¦¼(í‘œì‹œìš©)
        scores = _normalize_labels(scores)
        scores = _round_scores(scores)

        # === speaker â†’ ì‹¤ì œ userId ë³€í™˜ ===
        uid = _resolve_user_id(emo, request.role_binding)   # ë¬¸ìì—´(UUID/ID)
        alias = _alias_of(uid, request.role_binding) if uid is not None else (emo.speaker or None)

        analyzed_emotions.append(
            EmotionResponse(
                speaker=(str(uid) if uid is not None else None),  # âœ… ê·œê²©: ì‹¤ì œ userId
                userId=(str(uid) if uid is not None else None),
                alias=alias,
                sentence=emo.sentence,
                scores=scores,
                emotion_label=label,
                confidence=float(confidence),
                analyzed_at=datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
                sent_at=emo.sent_at,
            )
        )
        # ì»¨í…ìŠ¤íŠ¸ëŠ” ì›ë³¸ ë°œí™”ì ë¬¸ìì—´ ìœ ì§€í•´ë„ ë¬´ë°©(ëª¨ë¸ ë‚´ë¶€ ë¬¸ë§¥ìš©)
        history.append(current)

    # === ì§‘ê³„ ===
    aggregated = calculate_aggregated_user_centric(
        emotions=analyzed_emotions,
        start_at=request.chat_session.start_at,
        end_at=request.chat_session.end_at,
        role_binding=request.role_binding,
    )

    return {
        "chat_session": to_dict(request.chat_session),
        "emotions": [to_dict(e) for e in analyzed_emotions],
        "aggregated": aggregated
    }
